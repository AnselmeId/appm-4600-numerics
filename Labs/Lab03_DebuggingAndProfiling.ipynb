{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu-applied-math/appm-4600-numerics/blob/main/Labs/Lab03_DebuggingAndProfiling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3: Debugging and profiling code\n",
        "\n",
        "Components\n",
        "- TA demonstration\n",
        "  - The TA will show his/her debugging and profiling setup in VS Code.\n",
        "1. Debug code\n",
        "    - Specifically, we'll have the debugger stop inside someone else's code!\n",
        "2. Profiling code\n",
        "    - Walk through a short demo\n",
        "    - Students will then profile code themselves\n",
        "    - Show a few alternative (hacky) methods\n",
        "\n",
        "Learning objectives\n",
        "- Understand that debuggers and profilers exist and make your life easier\n",
        "- How to use a debugger within a Jupyter notebook\n",
        "- How to profile code\n",
        "\n",
        "Copyright 2025, Department of Applied Mathematics, University of Colorado Boulder. Released under the BSD 3-Clause License\n",
        "\n",
        "\n",
        "## Intro\n",
        "\n",
        "As our example today, we'll look at code for computing the matrix exponential, $e^A$. You should remember this from taking matrix methods APPM 3310.  If $A$ is diagonalizable, then we can compute $e^A$ using eigenvalues; if $A$ is not diagonalizable, it's a bit more complicated. Regardless, computing $e^A$ *efficiently* and *stably* is somewhat challenging and is a [classic problem](https://epubs.siam.org/doi/pdf/10.1137/S00361445024180) in numerical analysis.\n",
        "\n",
        "We'll use the standard `scipy.linalg` package to do this for us, and demonstrate how we can debug and profile code, even when we didn't write the code ourselves!\n",
        "\n",
        "This lab was tested with SciPy versions 1.11.1 and 1.16.1.  We *hope* it works with most other recent versions!\n",
        "\n",
        "Note: we recommend you download this entire `.ipynb` notebook and run it locally on your computer. You can download it via navigating our github site, or directly from [`https://raw.githubusercontent.com/cu-applied-math/appm-4600-numerics/refs/heads/main/Labs/Lab03_DebuggingAndProfiling.ipynb`](https://raw.githubusercontent.com/cu-applied-math/appm-4600-numerics/refs/heads/main/Labs/Lab03_DebuggingAndProfiling.ipynb)"
      ],
      "metadata": {
        "id": "YCpKTtz2UNT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "print(scipy.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDTqh1AThCUH",
        "outputId": "e2617153-9907-4a32-8eea-19cae88ea426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Debugging\n",
        "Note: we **highly** suggest running this in an editor like VS Code, or at least Jupyter Lab (not a plain Jupyter Notebook). You can debug in colab, but it's actually harder because you have to use some command line debugging skills. See this article [Debugging in Google Colab](https://www.geeksforgeeks.org/data-science/debugging-in-google-colab/) if you're curious (it uses the `ipdb` package).\n",
        "\n",
        "Note: If using a local editor, like VSCode, there may be a setting that by default does **not** let you debug code from libraries/packages. To make sure you can debug the scipy code, do the following:\n",
        "1. Open the VSCode settings (one way to do this is to click on the gear icon in the lower left hand corner).\n",
        "2. In the settings search bar, search \"debug just my code\".\n",
        "3. This should return a setting/checkbox tilted \"Jupyter: Debug Just My Code\". By default, this is checked/enabled. **Uncheck/disable** this setting.\n",
        "\n",
        "Now you should be able to debug the scipy code.\n",
        "\n",
        "There may be issues in Jupyter Lab with debugging external code as well. If you really cannot get it to work, let the TA know, and instead write your own code and step through it with the debugger.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Run the following code using your IDE, like VS Code. Inside the `expm` function, there is a line of code `m, s = pick_pade_structure(Am)`.\n",
        "\n",
        "**Deliverable**\n",
        "\n",
        "For the matrix $A$ below, when it is passed into `expm`, what is the value of `m` from the `m, s = pick_pade_structure(Am)` line inside the Scipy code?"
      ],
      "metadata": {
        "id": "p1kd3WU3UJHE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb6e2a-P2FQ8",
        "outputId": "60c12c64-2407-4cae-baae-0f37da304ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09]\n",
            " [0.1  0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19]\n",
            " [0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29]\n",
            " [0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39]\n",
            " [0.4  0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49]\n",
            " [0.5  0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59]\n",
            " [0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69]\n",
            " [0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79]\n",
            " [0.8  0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89]\n",
            " [0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99]]\n"
          ]
        }
      ],
      "source": [
        "import scipy.linalg as sla\n",
        "import numpy as np\n",
        "\n",
        "A = np.arange(int(1e2)).reshape(10,10)/100\n",
        "print(A)\n",
        "eA = sla.expm(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Profiling Code\n",
        "\n",
        "Profiling code refers to looking at running code and noticing what parts of the code take a long time, as well as memory usage.  For memory, you might look at what parts of the code require a lot of memory, or where memory leaks are, or at the cache miss rate, etc.\n",
        "\n",
        "We're not going to focus on memory profiling, but instead on time (aka speed) profiling.  A profiler tells us which parts of the code took a long time.  Some profiling tells us which **functions** take a while, other types of profiling tell us which **lines** of code take a while. Today we'll do the latter.\n",
        "\n",
        "There are some caveats: to do profiling, the profiler adds some extra overhead, so everything runs a bit slower, and you don't get a 100% accurate picture of exactly how long each part of the code takes. Usually it's accurate enough to give you an idea of where the slowish parts are.\n",
        "\n",
        "Some programmers avoid formal profiling but just adding timing statements into their code (see section 2c for a  few ways to do this). Sometimes this is easy to do and sufficient, but other times it's not systematic enough and takes more effort than you need; it's also a problem if you want to profile some library code where you don't want to have to edit the files.\n",
        "\n",
        "### 2a. Example usage\n",
        "\n",
        "We're going to use the `line_profiler` package, so let's first check if it is installed (and if not, we'll install it):"
      ],
      "metadata": {
        "id": "aqnu66yxC3vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import line_profiler\n",
        "    print(f\"The package 'line_profiler' is installed.\")\n",
        "except ModuleNotFoundError:\n",
        "    print(f\"The package 'line_profiler' is NOT installed.\")\n",
        "    # To install it via PIP, we can do the following:\n",
        "    import subprocess\n",
        "    subprocess.check_call(['pip', 'install', 'line_profiler'])\n",
        "    # or, just run: !pip install line_profiler     from within jupyter\n",
        "    # or, just run:  pip install line_profiler     from a command line\n",
        "    # or, if using conda, run:   conda install conda-forge::line_profiler     from a command line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY6oESW6UZZJ",
        "outputId": "7d9a6849-2bc4-4ef0-e02a-999df5900c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The package 'line_profiler' is NOT installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use it. There are different ways to use it. We'll use it in one manner which works well with jupuyter notedbooks.  The following is an ipython/jupyter specific command (you only need to run this once per session):"
      ],
      "metadata": {
        "id": "42HO5D-hVAqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext line_profiler"
      ],
      "metadata": {
        "id": "sLLxAwS82TFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's have some code to profile. Below is some silly code that does the computation $$f(n) = \\sum_{k=1}^n k$$ in a few different ways."
      ],
      "metadata": {
        "id": "5sm8ynM7VNP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_python(n):\n",
        "  sum = 0.\n",
        "  for k in range(n+1):\n",
        "      sum += k\n",
        "  return sum\n",
        "\n",
        "def sum_numpy(n):\n",
        "  nList = np.arange(n+1)\n",
        "  sum   = np.sum(nList)\n",
        "  return sum\n",
        "\n",
        "def my_sum(n):\n",
        "  \"\"\" returns the sum of k from k = 1 ... n \"\"\"\n",
        "  s1 = sum_python(n)\n",
        "  s2 = sum_numpy(n)\n",
        "  s3 = n*(n+1)/2  # use the closed-form formula, cf.  https://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%E2%8B%AF\n",
        "  assert np.isclose(s1,s2), \"The first two methods gave different values :-( )\"\n",
        "  assert np.isclose(s2,s3), \"The second two methods gave different values :-( )\"\n",
        "\n",
        "  return s1\n",
        "\n",
        "my_sum(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VGsmH5E2und",
        "outputId": "c7e96503-49ad-4207-bfd5-b52c6bca3675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500500.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how to use the line profiler, which will tell us which lines are taking up most of the time.\n",
        "\n",
        "Note: this works better in an IDE like VS Code. It *kinda* works in Colab (it may only tell you the line number)\n",
        "\n",
        "We'll use it in the following form:\n",
        "`%lprun -f name_of_fcn  big_fcn(...)`\n",
        "where `big_fcn(...)` is the code that you are going to call, and `name_of_fcn` is the *part* of that code that you want to investigate line-by-line.\n",
        "\n",
        "For example:"
      ],
      "metadata": {
        "id": "hIVkRK3XVcu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%lprun -f my_sum my_sum(1000)"
      ],
      "metadata": {
        "id": "apXRH9-UVcLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of that tells us that `sum_python` takes about 70% of the total time (this varies... run the above cell a few times to get an idea of the average), and `sum_numpy` takes about 10% of the time, and the rest of the time is spent on the `assert` statements.\n",
        "\n",
        "So let's take a deep dive on the `sum_python` code:"
      ],
      "metadata": {
        "id": "vq_GbAWdWWw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%lprun -f sum_python my_sum(1000)"
      ],
      "metadata": {
        "id": "6DlNd_YaV99d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of this tells is that the line `for k in range(n+1):` takes 50% of the time, and the `sum += k` takes another 50%. This means that the actual loop itself is slow, not the computation in the loop. That's not uncommon for interpreted languages like Matlab and Python (hence the emphasize on \"vectorized\" code).\n",
        "\n",
        "We can also take a deep dive on the `sum_numpy` code:"
      ],
      "metadata": {
        "id": "BYyq7MO1Wa_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%lprun -f sum_numpy my_sum(1000)"
      ],
      "metadata": {
        "id": "PBdXMM9-W-Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b: Your task"
      ],
      "metadata": {
        "id": "UJ3Y-VeBC-HJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverable**\n",
        "\n",
        "Run the code below, and find the **3 most expensive lines of code** from within the scipy.linalg.expm function"
      ],
      "metadata": {
        "id": "6q_T038_XNbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(123456)\n",
        "A = rng.standard_normal( (3000,3000) )/1e2\n",
        "eA = sla.expm(A)"
      ],
      "metadata": {
        "id": "UqKmJWsE4Emg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're curious and wanted to look at even lower level functions, it doesn't always work, because some functions are not implemented in Python, so you can't see their source code."
      ],
      "metadata": {
        "id": "D74dZtt9f6ZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c. Alternatives\n",
        "\n",
        "Instead of doing a formal profiler, you can add in manual timing statements. This is less systematic, but sometimes (due to its simplicity) it's enough.  Below are some examples.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Go through the examples below"
      ],
      "metadata": {
        "id": "-86972SR1i4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `timeit`\n",
        "\n",
        "First, let's use the **timeit** package. You can load this like `immport timeit` and use it explicitly, but in a jupyter/ipython notebook, the easiest way to use it is with **line magics** or **cell magics** (i.e., lines that start with `%` or `%%`, respectively).\n",
        "\n",
        "The idea of **timeit** is that it runs your code a few times to get a good average value\n",
        "\n",
        "Below is an example usage of **line magics**"
      ],
      "metadata": {
        "id": "lNonfuwH2pte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(1e4)\n",
        "%timeit sum_python(n)\n",
        "%timeit sum_numpy(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgLjeQ5N2bAn",
        "outputId": "b9766337-4be7-4af4-d1ca-1d61252f9533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25 ms ± 266 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "16.6 µs ± 2.85 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and here's a **cell magic**. It will time the entire cell (so in this case, it doesn't tell us which line was slower)"
      ],
      "metadata": {
        "id": "1zr8AXXP3BNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "n = int(1e4)\n",
        "sum_python(n)\n",
        "sum_numpy(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3-9jlFg2iGf",
        "outputId": "b0c64c03-5e09-4bb8-f9a9-2f21b6007675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.27 ms ± 271 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can get fancy if you want, and give it flags.  `r` tells is how many times to repeat the full run, and `n` is how many reps per run. (It generaly guesses good values for these based on how fast the program runs)"
      ],
      "metadata": {
        "id": "OYd1Wf7z3LaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -o -r 2 -n 1\n",
        "# n for number of times to run the code, r to repeat the full runs\n",
        "sum_numpy(n)\n",
        "\n",
        "tmStructure = _  # this _ is the result of the previous computation\n",
        "tmStructure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0lZ-AYH3dJ9",
        "outputId": "8ec4fab9-e6ca-4994-a876-65c7914d05fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.3 µs ± 38.4 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TimeitResult : 74.3 µs ± 38.4 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `time`\n",
        "\n",
        "We can also use the **time** package, which doesn't do any averaging for us:"
      ],
      "metadata": {
        "id": "caOvjX7b3tIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()  # Record the start time\n",
        "sum_numpy(n)\n",
        "end_time = time.time()    # Record the end time\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time} seconds\")\n",
        "\n",
        "# or...\n",
        "start_perf_counter = time.perf_counter()\n",
        "sum_numpy(n)\n",
        "end_perf_counter = time.perf_counter()\n",
        "\n",
        "execution_time_perf = end_perf_counter - start_perf_counter\n",
        "print(f\"Execution time (perf_counter): {execution_time_perf} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSNdWD7e3gkg",
        "outputId": "4f0762bc-bdeb-4db6-b1af-cf698157a481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.00028061866760253906 seconds\n",
            "Execution time (perf_counter): 0.00016296700005113962 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and like the `timeit` package, the `time` package also has **line magics** and **cell magics**:"
      ],
      "metadata": {
        "id": "sxtRt9SH336K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Line magics\n",
        "%time sum_python(n)\n",
        "%time sum_numpy(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANCUzHiF32oe",
        "outputId": "f8a94857-a2aa-48c9-c933-eff2f59e00d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.06 ms, sys: 0 ns, total: 1.06 ms\n",
            "Wall time: 1.07 ms\n",
            "CPU times: user 161 µs, sys: 0 ns, total: 161 µs\n",
            "Wall time: 144 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(50005000)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell magic\n",
        "%%time\n",
        "sum_python(n)\n",
        "sum_numpy(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql4Z0GAN4Bcm",
        "outputId": "7c04fc49-b2bb-44be-b957-9a3c0593c3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.31 ms, sys: 2 µs, total: 1.31 ms\n",
            "Wall time: 1.29 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(50005000)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deliverables for 2c\n",
        "None.  Just make sure to turn in your work for parts 1 and 2b"
      ],
      "metadata": {
        "id": "kitQeoGl4U7e"
      }
    }
  ]
}
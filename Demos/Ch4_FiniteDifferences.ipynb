{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch4_FiniteDifferences.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXnogT6XGtvaZuDQGbz3VZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenbeckr/numerical-analysis-class/blob/student/Demos/Ch4_FiniteDifferences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncf6wW9Bz6ju"
      },
      "source": [
        "# First exploration of finite-difference approximations to derivatives\n",
        "\n",
        "- Task 1: try the simple forward differences formula to approximate the derivative of $f(x)=\\sin(x)$. The formula is:\n",
        "$$f'(x) \\approx \\frac{ f(x+h)-f(x) }{h}$$\n",
        "Try this for a range of stepsizes $h$. Can we make the approximation (aka \"truncation\") error arbitrarily small?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh4EU9mHPnxy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Approximate the derivative of sin(x)\n",
        "f   = lambda x : np.sin(x)\n",
        "trueDerivative = lambda x : np.cos(x)\n",
        "\n",
        "def twoPointForwardDifferences( f, x, h ):\n",
        "  \"\"\" The simplest, plain vanilla finite difference approx\"\"\"\n",
        "  return ( f(x+h) - f(x) )/h\n",
        "\n",
        "# Pick some point x at which we want the derivative\n",
        "x   = 2.\n",
        "df      = trueDerivative(x)\n",
        "twoPointF= lambda h : twoPointForwardDifferences( f, x, h)\n",
        "\n",
        "# Pick stepsizes h\n",
        "hList   = np.logspace(-1,-12,30)\n",
        "for h in hList:\n",
        "  print(\"h is {:.2e} and error in approximation is {:.2e}\".format(h, np.abs( df - twoPointF(h) )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2NLL1NOp5fw"
      },
      "source": [
        "# Pick stepsizes h\n",
        "hList   = np.logspace(-1,-12,30)\n",
        "\n",
        "# Plot\n",
        "plt.loglog( hList, np.abs( df - twoPointF(hList) ), 'o-', label=\"2 Pt Forward Diff\" );\n",
        "plt.xlabel(\"h\");\n",
        "plt.ylabel(\"Error\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l31kh-XN8MMJ"
      },
      "source": [
        "## Getting fancier: adding in other methods\n",
        "- Task 2: try other finite difference methods (e.g, 3 point forward differences; 3 point centered differences; 5 point centered differences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9VWv8jKzRiK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Approximate the derivative of sin(x)\n",
        "f   = lambda x : np.sin(x)\n",
        "trueDerivative = lambda x : np.cos(x)\n",
        "\n",
        "def twoPointForwardDifferences( f, x, h ):\n",
        "  \"\"\" The simplest, plain vanilla finite difference approx\"\"\"\n",
        "  return ( f(x+h) - f(x) )/h\n",
        "def threePointForwardDifferences( f, x, h):\n",
        "  \"\"\"Eq. (4.4) in the Burden and Faires book\"\"\"\n",
        "  return (-3*f(x)+4*f(x+h)-f(x+2*h))/(2*h)\n",
        "def threePointCenteredDifferences( f, x, h ):\n",
        "  \"\"\" Book calls it 3 points, since it sort of includes f(x) \"\"\"\n",
        "  return ( f(x+h) - f(x-h) )/(2*h)\n",
        "def fivePointCenteredDifferences( f, x, h ):\n",
        "  \"\"\" Eq. (4.6) in Burden and Faires book \"\"\"\n",
        "  return ( f(x-2*h) - 8*f(x-h) + 8*f(x+h) - f(x+2*h) )/(12*h)\n",
        "\n",
        "# Pick some point x at which we want the derivative\n",
        "x   = 2.\n",
        "df      = trueDerivative(x)\n",
        "twoPointF= lambda h : twoPointForwardDifferences( f, x, h)\n",
        "threePointC= lambda h : threePointCenteredDifferences( f, x, h)\n",
        "threePointF= lambda h : threePointForwardDifferences( f, x, h)\n",
        "fivePointC= lambda h : fivePointCenteredDifferences( f, x, h)\n",
        "\n",
        "# Pick stepsizes h\n",
        "hList   = np.logspace(-1,-12,20)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,8)) \n",
        "plt.loglog( hList, np.abs( df - twoPointF(hList) ), 'o-', label=\"2 Pt Forward Diff\" );\n",
        "plt.loglog( hList, np.abs( df - threePointC(hList) ), 'o-', label=\"3 Pt Centered Diff\" );\n",
        "plt.loglog( hList, np.abs( df - threePointF(hList) ), 'o-', label=\"3 Pt Forward Diff\" );\n",
        "plt.loglog( hList, np.abs( df - fivePointC(hList) ), 'o-', label=\"5 Pt Centered Diff\" )\n",
        "plt.legend();\n",
        "plt.xlabel(\"h\");\n",
        "plt.ylabel(\"Error\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfyNaQwHMEne"
      },
      "source": [
        "## Can we estimate how low the error can be?\n",
        "It's a trade off between truncation error (low $h$ is good), and roundoff error (low $h$ is bad)\n",
        "- Task 3: can we predict how low each method gets? Assume error looks like\n",
        "$$\\epsilon/h + h^k$$ where $k$ is the order, and use `sympy` to minimize this (e.g., differentiate it and set it equal to 0).  You may want to declare $\\epsilon$ as a symbol like:  `e = sym.symbols('\\epsilon',positive=True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq6GmiOA8ZYT"
      },
      "source": [
        "import sympy as sym\n",
        "from sympy import init_printing\n",
        "init_printing()\n",
        "\n",
        "h = sym.symbols('h')\n",
        "e = sym.symbols('\\epsilon',positive=True)\n",
        "g = e/h + h\n",
        "d = sym.diff( g,  h)\n",
        "d\n",
        "h0 = list( sym.solveset( d, h, domain=sym.S.Reals) )[0]\n",
        "print(\"Order 1, (optimal h, value-at-optimal)\")\n",
        "h0, g.subs(h,h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2osFNJEJiCH"
      },
      "source": [
        "g = e/h + h**2\n",
        "d = sym.diff( g,  h)\n",
        "h0 = list( sym.solveset( d, h, domain=sym.S.Reals) )[0]\n",
        "print(\"Order 2\")\n",
        "h0, g.subs(h,h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0pHzo-fJqlw"
      },
      "source": [
        "g = e/h + h**3\n",
        "d = sym.diff( g,  h)\n",
        "h0 = list( sym.solveset( d, h, domain=sym.S.Reals) )[0]\n",
        "print(\"Order 3\")\n",
        "h0, g.subs(h,h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYoXlUH3Jszp"
      },
      "source": [
        "g = e/h + h**4\n",
        "d = sym.diff( g,  h)\n",
        "h0 = list( sym.solveset( d, h, domain=sym.S.Reals) )[0]\n",
        "print(\"Order 4\")\n",
        "h0, g.subs(h,h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cj-UDTaNfpi"
      },
      "source": [
        "### And put these in the plot\n",
        "- 2 pt forward diff is $O(h)$\n",
        "- 3 pt forward diff is $O(h^2)$\n",
        "- 3 pt centered diff is $O(h^2)$\n",
        "- 5 pt centered diff is $O(h^4)$\n",
        "\n",
        "Note that our error estimates are a bit crude, as we ignore constants. The condition number of $\\sin(x)$ does depend on the value of $x$, so you could try different values of $x$ to see if that affects anything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp1Rc6OxNBN3"
      },
      "source": [
        "# So add to the plot\n",
        "plt.figure(figsize=(10,8)) \n",
        "plt.loglog( hList, np.abs( df - twoPointF(hList) ), 'o-', label=\"2 Pt Forward Diff\" );\n",
        "plt.loglog( hList, np.abs( df - threePointC(hList) ), 'o-', label=\"3 Pt Centered Diff\" );\n",
        "plt.loglog( hList, np.abs( df - threePointF(hList) ), 'o-', label=\"3 Pt Forward Diff\" );\n",
        "plt.loglog( hList, np.abs( df - fivePointC(hList) ), 'o-', label=\"5 Pt Centered Diff\" )\n",
        "plt.legend();\n",
        "plt.xlabel(\"h\");\n",
        "plt.ylabel(\"Error\");\n",
        "\n",
        "# And can we predict the values of h which gives us the smallest amount?\n",
        "eps = np.finfo(float).eps\n",
        "eps**(1/2)\n",
        "eps**(1/4)\n",
        "plt.vlines( eps**(1/2), *plt.gca().get_ylim() ,linestyles='--',colors=\"C0\");\n",
        "plt.vlines( eps**(1/3), *plt.gca().get_ylim() ,linestyles='--',colors=\"C1\");\n",
        "plt.vlines( eps**(1/5), *plt.gca().get_ylim() ,linestyles='--',colors=\"C3\");\n",
        "\n",
        "plt.hlines( eps**(1/2), *plt.gca().get_xlim() ,linestyles='--',colors=\"C0\");\n",
        "plt.hlines( eps**(2/3), *plt.gca().get_xlim() ,linestyles='--',colors=\"C1\");\n",
        "plt.hlines( eps**(4/5), *plt.gca().get_xlim() ,linestyles='--',colors=\"C3\");"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}